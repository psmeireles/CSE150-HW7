{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsFile = open('general/words.txt')\n",
    "words = []\n",
    "for word in wordsFile:\n",
    "    words.append(word.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dict with every category's nGram count distribution\n",
    "categories = defaultdict()\n",
    "for category in ['general', 'business', 'entertainment', 'politics', 'sport', 'tech']:\n",
    "    ngrams = []\n",
    "    for n in ['uni', 'bi', 'tri', 'four', 'five']:\n",
    "        if category == 'general':\n",
    "            filename = f'{category}/{n}grams.txt'\n",
    "        else:\n",
    "            filename = f'{category}/{category}_{n}grams.txt'\n",
    "        \n",
    "        file = open(filename)\n",
    "        \n",
    "        ngramVector = []\n",
    "        for l in file:\n",
    "            if n == 'uni':\n",
    "                ngramVector.append(int(l))\n",
    "            else:\n",
    "                ngramVector.append([int(x) for x in l.split()])\n",
    "        file.close()\n",
    "        \n",
    "        # precomputing probabilities for unigrams\n",
    "        if n == 'uni':\n",
    "            uniSum = sum(ngramVector)\n",
    "            ngramVector = [x/uniSum for x in ngramVector]\n",
    "            \n",
    "        ngrams.append(ngramVector)\n",
    "    categories[category] = ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsUnigram(categories, category):\n",
    "    # Returns the category's unigram probabilities for every word\n",
    "    return categories[category][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsNGram(evidence, categories, category, words):\n",
    "    # Returns the category's nGram probabilities for every nGrams\n",
    "    n = len(evidence.split())\n",
    "    corpus = categories[category][n]\n",
    "    counts = [[words[v[n]], v[n]] for v in corpus if [words.index(e) for e in evidence.split()] == v[:n]]\n",
    "    countsSum = sum([v[1] for v in counts])\n",
    "    probabilities = [[v[0], v[1]/countsSum] for v in counts]\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramProbability(word, probVector, words):\n",
    "    # Returns the category's unigram probability for a specific word\n",
    "    return probVector[words.index(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGramProbability(word, probVector):\n",
    "    # Returns the category's nGram probability for a specific nGram\n",
    "    prob = [v[1] for v in probVector if v[0] == word]\n",
    "    if len(prob) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixedProb(word, words, uniDist, nGramsDists, lambdas):\n",
    "    # Returs the mixed probability considering all nGrams\n",
    "    mixed = lambdas[0]*unigramProbability(word, uniDist, words)\n",
    "    for i in range(0, len(nGramsDists)):\n",
    "        mixed += lambdas[i+1]*nGramProbability(word, nGramsDists[i])\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNextWord(evidence, categories, category, probsUni, lambdas=[0.2]*5):\n",
    "    # Predicts the next word given a reference text\n",
    "    evidenceWords = evidence.split()\n",
    "    n = len(evidenceWords)\n",
    "    sumRelevantLambdas = sum(lambdas[:n+1])\n",
    "    normLambda = [x/sumRelevantLambdas for x in lambdas[:n+1]]\n",
    "    nGramsDists = []\n",
    "    \n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "    \n",
    "        futures = [winprocess.submit(executor, probsNGram, ' '.join(evidenceWords[-i:]), categories, category, words)\\\n",
    "                  for i in range(1, n+1)]\n",
    "\n",
    "        concurrent.futures.wait(futures)\n",
    "        nGramsDists = [f.result() for f in futures]\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        newEvidence = ' '.join(evidenceWords[-i:])\n",
    "        nGramsDists.append(probsNGram(newEvidence, categories, category, words))\n",
    "    \n",
    "    \n",
    "    probabilities = []\n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        args = categories, category, words, probsUni, nGramsDists, normLambda\n",
    "        futures = [winprocess.submit(executor, calculateMixedProbs, group, *args)\\\n",
    "                  for group in grouper(words, 1000)]\n",
    "\n",
    "        concurrent.futures.wait(futures)\n",
    "        probabilities = list(zip(words, [f.result() for f in futures]))\n",
    "\n",
    "    \"\"\"\n",
    "    for word in words:\n",
    "        mixed = mixedProb(word, words, probsUni, nGramsDists, normLambda)\n",
    "        probabilities.append([word, mixed])\n",
    "    \n",
    "    \n",
    "    probabilities = sorted(probabilities, key = lambda x:-x[1])\n",
    "    return [v[0] for v in probabilities[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllPredictions(evidence, categories, category, probsUni, lambdas=[0.2]*5):\n",
    "    # Returns the 3 most probable fivegrams\n",
    "    recommendedWords = []\n",
    "    newEvidence = evidence\n",
    "    for i in range(0, 15):\n",
    "        newWords = predictNextWord(newEvidence, categories, 'general', \\\n",
    "                            probsUnigram(categories, 'general'))\n",
    "        if i == 0:\n",
    "            for j in range(0, len(newWords)):\n",
    "                recommendedWords.append([newWords[j]])\n",
    "        else:\n",
    "            recommendedWords[i%5].append(newWords[0])\n",
    "\n",
    "        if i%5 == 0:\n",
    "            newEvidence = ' '.join(evidence.split()[-3:] + [recommendedWords[i/5][i%5]])\n",
    "        else:\n",
    "            newEvidence = ' '.join(newEvidence.split()[-3:] + [recommendedWords[i/5][i%5]])\n",
    "    return recommendedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hands', 'belief', 'the']"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "predictNextWord('tv future in the', categories, 'general', \\\n",
    "                        probsUnigram(categories, 'general'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where thieves would set\n",
      "Wall time: 8min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evidence = 'this is one example'\n",
    "for i in range(0, 5):\n",
    "    newWord = predictNextWord(evidence, categories, 'general', \\\n",
    "                        probsUnigram(categories, 'general'))\n",
    "    evidence = ' '.join(evidence.split()[-3:] + [newWord])\n",
    "print(evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
